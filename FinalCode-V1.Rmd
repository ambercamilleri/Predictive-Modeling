---
title: "Final Code"
output: html_document
---

```{r}
rm(list=ls())
#setwd("~/R/Predictive Modeling AirBnB Project")
listings_raw = read.csv("listings.csv") #open the .csv file
attach(listings_raw)

library(dplyr)
listings_short = select(listings_raw, id, name, latitude, longitude, room_type, price, guests_included, minimum_nights, review_scores_rating, cancellation_policy, host_is_superhost, number_of_reviews, number_of_reviews_ltm, bathrooms, bedrooms, beds, bed_type)

clean_listings = subset(listings_short, minimum_nights <= 14) #removes 766 entries

library(tidyr)
#Remove '$' from 'price'
clean_listings$price = substring(clean_listings$price,2)

x=clean_listings$price
x = as.numeric(gsub(",","",x))
clean_listings$price = x

clean_listings = subset(clean_listings, !(is.na(price)))
```


Now that we know what the dataset looks like, we can see it contains over 100 columns, some of which will not be useful for our purpose. We have chosen several variables we are interested in exploring further, so we will create a new dataset that is limited to just those variables. 

Typical Airbnb listings are vacation-type rentals that are rented out for a time period between one day and two weeks. However, we can see that some Airbnb hosts are have a minimum nights requirement of much longer than this. For example:

```{r}
max(clean_listings$price)
min(clean_listings$price)
sd(clean_listings$price)
hist(clean_listings$price, main = "Price distribution in initial dataset", xlab="Price")
```

These hosts may be using Airbnb to help them find a long-term tenant at their listing location. At this time, we will focus only on the typical Airbnb model and remove listings which have a minimum nights requirement of more than 14 days. 



```{r Checking all variables and cleaning data}
clean_listings = subset(clean_listings, price > 0)

#REVIEW SCORES RATING
clean_listings$has_reviews = !(is.na(clean_listings$review_scores_rating))
#Impute mean review score to missing values
list_with_review_scores = subset(clean_listings, !(is.na(review_scores_rating)))
clean_listings$review_scores_rating = clean_listings$review_scores_rating %>% replace_na(mean(list_with_review_scores$review_scores_rating))

#HOST IS SUPERHOST
clean_listings = subset(clean_listings, !(host_is_superhost == ""))

#BATHROOMS
clean_listings = subset(clean_listings, !(is.na(bathrooms)))

#BEDROOMS
clean_listings = subset(clean_listings, !(is.na(bedrooms)))

#BEDS
clean_listings = subset(clean_listings, !(is.na(beds)))

#cleaning process removed a total of 32 rows for missing values
#######################################################################
#FINAL CHECK THAT DATA IS CLEAN
sum(is.na(clean_listings))
sum(clean_listings == "")
```


```{r}
#Drop 'id' column
clean_listings$id <-NULL
#Drop 'name' column
clean_listings$name <-NULL
head(clean_listings)

clean_listings_price500 = subset(clean_listings, price <= 500)

#Remove decimal values (bc we are only keeping values <=500 we can keep 3 sig digits)
format(clean_listings_price500$price, digits=3)

max(clean_listings_price500$price)
min(clean_listings_price500$price)
sd(clean_listings_price500$price)
hist(clean_listings_price500$price, main = "Price distribution in cleaned dataset", xlab="Price")
```





Correlation Matrix (Numeric Variables Only)
-------------------------------------------
```{r}
library(fastDummies)
library(Hmisc)
#install.packages('corrplot')
library(corrplot)
clean_listings = data.frame(clean_listings_price500)
attach(clean_listings)
head(clean_listings) #examine the data in window
```


```{r}
#Drop non-numeric columns
clean_listings$room_type <-NULL
clean_listings$cancellation_policy <- NULL
clean_listings$host_is_superhost <- NULL
clean_listings$bed_type <- NULL
head(clean_listings)
```

```{r}
names(clean_listings) <- c("lat", "long", "price", "guests", "min_nts", "rs", "numr", "numr_ltm", "bathr", "bedr", "beds", "hasr")
head(clean_listings)
```

```{r, include=FALSE}
cor(clean_listings, use="pairwise.complete.obs")
```

```{r}
clean_listings.cor = cor(clean_listings)
```

```{r}
clean_listings.cor = cor(clean_listings, method = c("spearman"))
```

Run the correlation matrix with significance levels (p-values)
```{r, include=FALSE}
clean_listings.rcorr = rcorr(as.matrix(clean_listings))
```

```{r}
clean_listings.coeff = clean_listings.rcorr$r
clean_listings.p = clean_listings.rcorr$P
```


Visualizing the Correlation Matrix (Numeric Variables Only)
-----------------------------------------------------------
```{r}
{plot.new(); dev.off()}
corrplot.mixed(clean_listings.cor)
#corrplot(clean_listings.cor, tl.pos="n")
```





Correlation Matrix (With Dummy Variables)
-----------------------------------------
```{r}
clean_listings = data.frame(clean_listings_price500)
attach(clean_listings)
head(clean_listings) #examine the data in window
```


Create Dummy Variables for non-integer columns
```{r}
clean_listings = dummy_cols(clean_listings)
head(clean_listings)
```

```{r}
#Drop non-numeric columns
clean_listings$room_type <-NULL
clean_listings$cancellation_policy <- NULL
clean_listings$host_is_superhost <- NULL
clean_listings$bed_type <- NULL
head(clean_listings)
```

```{r}
names(clean_listings) <- c("lat", "long", "price", "guests", "min", "rs", "numr", "numr_ltm", "bathr", "bedr", "beds", "hasr", "rt_entire", "rt_priv", "rt_share", "cp_14", "cp_mod", "cp_flex", "cp_30", "cp_60", "cp_strict", "supert", "superf", "bt_real", "bt_futon", "bt_couch", "bt_airbed", "bt_pull" )
head(clean_listings)
```

```{r, include=FALSE}
cor(clean_listings, use="pairwise.complete.obs")
```

```{r}
clean_listings.cor = cor(clean_listings)
```

```{r}
clean_listings.cor = cor(clean_listings, method = c("spearman"))
```

Run the correlation matrix with significance levels (p-values)
```{r, include=FALSE}
clean_listings.rcorr = rcorr(as.matrix(clean_listings))
clean_listings.rcorr
```

```{r}
clean_listings.coeff = clean_listings.rcorr$r
clean_listings.p = clean_listings.rcorr$P
```

Visualizing the Correlation Matrix (With Dummy Variables)
---------------------------------------------------------
```{r}
{plot.new(); dev.off()}
corrplot.mixed(clean_listings.cor)
#corrplot(clean_listings.cor, tl.pos="n")
```




Predictor Plots
-----------------

```{r, include=FALSE}

clean_listings = data.frame(clean_listings_price500)
head(clean_listings) #examine the data in window
attach(clean_listings)
```


#Descriptive Statistics
```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...) {
    usr <- par("usr")
    on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- cor(x, y)
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    text(0.5, 0.5, txt)
}

pairs(cbind(price, latitude, longitude, guests_included, minimum_nights, review_scores_rating, cancellation_policy, host_is_superhost, number_of_reviews, number_of_reviews_ltm, bathrooms, bedrooms, beds, bed_type, has_reviews), 
      upper.panel= panel.smooth, 
      lower.panel = panel.cor)
```

```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...) {
    usr <- par("usr")
    on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- cor(x, y)
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    text(0.5, 0.5, txt)
}

pairs(cbind(price, bedrooms, room_type, bathrooms, number_of_reviews_ltm), 
      upper.panel= panel.smooth, 
      lower.panel = panel.cor)
```


```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...) {
    usr <- par("usr")
    on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- cor(x, y)
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    text(0.5, 0.5, txt)
}

pairs(cbind(price, review_scores_rating, number_of_reviews, number_of_reviews_ltm, has_reviews), upper.panel= panel.smooth, lower.panel = panel.cor)
```


```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...) {
    usr <- par("usr")
    on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- cor(x, y)
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    text(0.5, 0.5, txt)
}

pairs(cbind(price,bathrooms, bedrooms, beds, bed_type),
      upper.panel= panel.smooth, 
      lower.panel = panel.cor)
```


```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...) {
    usr <- par("usr")
    on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- cor(x, y)
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    text(0.5, 0.5, txt)
}

pairs(cbind(price, latitude, longitude), 
      upper.panel= panel.smooth, 
      lower.panel = panel.cor)
```


```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...) {
    usr <- par("usr")
    on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- cor(x, y)
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    text(0.5, 0.5, txt)
}

pairs(cbind(price, guests_included, minimum_nights, cancellation_policy, host_is_superhost), 
      upper.panel= panel.smooth, 
      lower.panel = panel.cor)
```




Price Distribution Map
-----------------------
```{r, echo=FALSE}
clean_listings = data.frame(clean_listings_price500)
head(clean_listings) #examine the data in window
attach(clean_listings)

library(ggplot2)
library(ggmap)
library(maptools)
library(ggthemes)
library(rgeos)
library(broom)
library(dplyr)
library(plyr)
library(grid)
library(gridExtra)
library(reshape2)
library(scales)
```

#Letâ€™s Make a Map of the Price Distribution by Location
```{r}
# Download a basemap using the ggmap package (PDF).
basemap <- get_stamenmap(bbox = c(left=-98.03,bottom=30.1,top=30.52,right=-97.52),maptype = "toner-lite")

# Plot price distribution by location (using latitude/longitude) 
prices_mapped_by_year <- ggmap(basemap) + 
  geom_point(data = clean_listings, aes(x = longitude, y = latitude, color = price), 
             size = 2.5) +
             scale_color_gradientn("Price per Night", colors = c("#9ddCEE","#46A5D3","#6E81BF","#8E76C9","#AF6BD4","#CF60DE","#F055E9"),
             labels = scales::dollar_format(prefix = "$")) +
  labs(title="Distribution AirBnB Prices in Austin,TX")

prices_mapped_by_year
```





Ridge Regression and Lasso Model
=================================

```{r}

clean_listings = data.frame(clean_listings_price500)
head(clean_listings) #examine the data in window
attach(clean_listings)
```
```{r}
range(review_scores_rating)
```


Validation Set
---------------
```{r}
x=model.matrix(price~.,clean_listings)
y=clean_listings$price

set.seed(1)
train=sample(1:nrow(x), nrow(x)/2)
test=(-train)
y.test=y[test]
```



Ridge Regression
-----------------
We will use the package `glmnet`, which does not use the model formula language, so we will set up on an `x` and `y`.
```{r}
library(glmnet)
```

Fit a ridge-regression model. This is achieved by calling `glmnet` with `alpha=0` 
```{r}
fit.ridge=glmnet(x,y,alpha=0)
plot(fit.ridge, xvar="lambda", label=TRUE)
```

Now we will use the `cv.glmnet` function to do the cross-validation
```{r}
cv.ridge=cv.glmnet(x,y,alpha=0)
plot(cv.ridge)
```



Lasso
------
Now we fit a lasso model; for this we use the default `alpha=1`
```{r}
fit.lasso=glmnet(x,y)
plot(fit.lasso, xvar="lambda", label=TRUE)
summary(fit.lasso)
```

Percentage of deviance or R^2 explained (may be an indication that the end of the plot is overfit)
```{r}
fit.lasso=glmnet(x,y)
plot(fit.lasso, xvar="dev", label=TRUE)
```

Cross Validation for Lasso
```{r}
cv.lasso = cv.glmnet(x, y)
plot(cv.lasso)
```

Extract the coefficient from the CV object, it'll pick the coefficient vector corresponding to the best model
```{r}
coef(cv.lasso)
```


Suppose we want to use our earlier train/validation division to select the `lambda` for the lasso.
```{r}
lasso.tr=glmnet(x[train,],y[train])
lasso.tr
```

So now we can make predictions on our left r data. That's indexes x by minus train.
If we take the dim of this prediction set we can see there are 4786 observations of the validation set 
and bc we have 70 values of lambda there will be 70 different columns in this prediction matrix
```{r}
pred=predict(lasso.tr, x[-train,])
dim(pred) 
```

Then we can look at our validation curve by by plotting RMSE as a function of Lambda
To find the RMSE:
(1) Compute our sum of squared errors
(2) Use apply to compute the means in each column of the squared errors
(3) Take the square root
```{r}
rmse=sqrt(apply((y[-train]-pred)^2,2,mean))
plot(log(lasso.tr$lambda),rmse,type="b", xlab="Log(lambda)")
```

Next, we can extract the base lambda.
We do this by indexing lambda in ascending order of rmse and picking out the index of the first (smallest) value.
```{r}
lam.best=lasso.tr$lambda[order(rmse)[1]]
lam.best
```

Now we can look at the coefficients corresponding to lam.best
That'll give us a subset of the coefficients (our coefficient vector)
```{r}
coef(lasso.tr, s=lam.best)
```

## Run Subset Selection, Forward, Backward, and Step-wise Selection
```{r}
library(leaps)

listings_cleaned= data.frame(clean_listings_price500)

attach(listings_cleaned)

########################
### Subset selection ###
########################

regfit.full = regsubsets(price~.,listings_cleaned)
summary(regfit.full)
reg.summary=summary(regfit.full)
which.max(reg.summary$adjr2)
which.min(reg.summary$bic)

#####################################################
## Forward, Backward, Stepwise Multiple Regression ##
#####################################################

listings_cleaned = dummy_cols(listings_cleaned)

logPrice = log(as.numeric(price))


airbnbx = listings_cleaned[,-c(3,4,8,9,15,16,19,20,27,32)] #price original columns for which dummy variables now exist

#fix(airbnbx)

n = dim(airbnbx)[1]
tr = sample(1:n,5000)

XXabb = model.matrix(~.*longitude*latitude, data=data.frame(scale(airbnbx)))[,-1]
ABBdata = data.frame(logPrice,XXabb)

null = lm(logPrice~1, data=ABBdata[tr,])
full = glm(logPrice~., data=ABBdata[tr,])

regForward = step(null, scope=formula(full), direction="forward", k=log(length(tr)))
regBack = step(full, direction="backward", k=log(length(tr)))
regStep = step(null, scope=formula(full), direction="both", k=log(length(tr)))
  
summary(regForward)
summary(regBack)
summary(regStep)

predict.fwd = exp(predict(regForward, ABBdata[-tr,]))
resid.fwd = price[-tr] - predict.fwd
rmse.fwd = sqrt(mean(resid.fwd^2))

predict.bwd = exp(predict(regBack, ABBdata[-tr,]))
resid.bwd = price[-tr] - predict.bwd
rmse.bwd = sqrt(mean(resid.bwd^2))

predict.step = exp(predict(regStep, ABBdata[-tr,]))
resid.step = price[-tr] - predict.step
rmse.step = sqrt(mean(resid.step^2))

coef(regStep)                 
```

